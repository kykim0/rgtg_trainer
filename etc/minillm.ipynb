{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kykim/miniconda3/envs/args/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model_name = \"kykim0/pythia-1b-tulu-v2-mix\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).eval().to(device)\n",
    "if not model.generation_config.pad_token_id: model.config.pad_token_id\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
    "uf_cleaned = load_dataset(\"allenai/ultrafeedback_binarized_cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def reward_fn(model, model_inputs, input_ids):\n",
    "    outputs = model(**model_inputs)\n",
    "\n",
    "    logits = outputs.logits # (B, L, V)\n",
    "    logits = logits - torch.mean(logits, dim=-1, keepdim=True)\n",
    "\n",
    "    mask = model_inputs[\"attention_mask\"]\n",
    "    logits = logits * mask.unsqueeze(-1) # set logits output by padding to 0\n",
    "\n",
    "    logits = logits[:, input_ids.size(-1)-1:, :]\n",
    "    mask = mask[:, input_ids.size(-1)-1:]\n",
    "\n",
    "    selection_value = torch.gather(logits[:, :-1, :], -1, model_inputs[\"input_ids\"][:, input_ids.size(-1):, None]).squeeze(-1)\n",
    "\n",
    "    print(f'model_inputs[\"inputs_ids\"]: {model_inputs[\"input_ids\"].shape}')\n",
    "    print(f'model_inputs[\"inputs_ids\"][]: {model_inputs[\"input_ids\"][:, input_ids.size(-1):, None].shape}')\n",
    "    print(f'logits[:, :-1, :]: {logits[:, :-1, :]}')\n",
    "    print(f'selection_value: {selection_value}')\n",
    "\n",
    "    current_logits = logits[:, :-1, :]\n",
    "    next_state_value = torch.logsumexp(current_logits, dim=-1)\n",
    "    next_state_value = next_state_value * mask[:, :-1]\n",
    "\n",
    "    print(f'current_logits: {current_logits}')\n",
    "    print(f'next_state_value: {next_state_value}')\n",
    "\n",
    "    scores = selection_value - next_state_value\n",
    "\n",
    "    assert all((~torch.isinf(scores.view(-1))) & (~torch.isnan(scores.view(-1))))\n",
    "    return scores\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def reward_fn_ours(t_model, model_inputs, input_ids):\n",
    "    from trl.trainer.utils import forward\n",
    "    query_response = model_inputs[\"input_ids\"]\n",
    "    context_length = input_ids.shape[1]\n",
    "    response = query_response[:, context_length:]\n",
    "\n",
    "    t_output = forward(t_model, query_response, tokenizer.pad_token_id)\n",
    "    t_logits = t_output.logits[:, context_length - 1 : -1]\n",
    "    print(f't_logits: {t_logits}')\n",
    "    t_all_logprob = F.log_softmax(t_logits, dim=-1)\n",
    "    t_logprob = torch.gather(t_all_logprob, 2, response.unsqueeze(-1)).squeeze(-1)\n",
    "    return t_logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_texts = [\n",
    "    \"hello how are you doing today?!\",\n",
    "    \"my name is Saemee. will you be my friend?\",\n",
    "]\n",
    "\n",
    "input_texts = []\n",
    "for query_text in query_texts:\n",
    "    messages = [{\"role\": \"user\", \"content\": query_text}]\n",
    "    input_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    input_texts.append(input_text)\n",
    "\n",
    "inputs = tokenizer(input_texts, return_tensors=\"pt\", padding=True)\n",
    "inputs = inputs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<|user|>\\nhello how are you doing today?!\\n<|assistant|>\\nHello! As an AI language model, I don't have feelings, but I'm functioning properly and ready to assist you with any questions or tasks you may have. How can I help you today?\",\n",
       " \"<|user|>\\nmy name is Saemee. will you be my friend?\\n<|assistant|>\\nOf course! I'd be happy to be your friend. What do you like to do for fun?\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=256,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    return_dict_in_generate=True,\n",
    "    output_scores=True,\n",
    ")\n",
    "logits = torch.stack(outputs.scores, dim=1)\n",
    "output_texts = tokenizer.batch_decode(outputs.sequences, skip_special_tokens=True)\n",
    "output_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_inputs[\"inputs_ids\"]: torch.Size([2, 67])\n",
      "model_inputs[\"inputs_ids\"][]: torch.Size([2, 41, 1])\n",
      "logits[:, :-1, :]: tensor([[[10.1872, -9.2653, 12.5619,  ..., -9.2280, -9.4637, -9.3478],\n",
      "         [18.3688, -9.4639, 26.1474,  ..., -9.4509, -9.6070, -9.4042],\n",
      "         [16.7981, -8.4010, 10.1527,  ..., -8.5817, -8.5789, -8.6190],\n",
      "         ...,\n",
      "         [15.5656, -7.1599, 17.2097,  ..., -7.1016, -7.2832, -7.2053],\n",
      "         [17.0417, -8.2916, 21.1121,  ..., -7.9137, -8.1858, -8.3586],\n",
      "         [33.3546, -7.4864, 13.4063,  ..., -7.5589, -7.4512, -7.4859]],\n",
      "\n",
      "        [[10.4974, -8.5801, 11.5164,  ..., -8.5373, -9.0073, -8.6803],\n",
      "         [14.3768, -5.2486, 13.2628,  ..., -5.0781, -5.0712, -5.0118],\n",
      "         [18.4907, -7.6095, 27.9769,  ..., -7.6975, -7.4529, -7.6503],\n",
      "         ...,\n",
      "         [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000]]],\n",
      "       device='cuda:0')\n",
      "selection_value: tensor([[21.5411, 26.1474, 30.5074, 32.3192, 29.5763, 30.1566, 31.6065, 33.1091,\n",
      "         34.7824, 35.9669, 34.1642, 29.8607, 30.3575, 30.3459, 32.4110, 30.3091,\n",
      "         31.3442, 28.0564, 28.0637, 30.0590, 30.5639, 32.6106, 32.7096, 33.7905,\n",
      "         30.7666, 35.8009, 30.8250, 36.3223, 31.0110, 33.2741, 32.9266, 34.9673,\n",
      "         29.7875, 34.5693, 30.1014, 33.2034, 29.3348, 28.1201, 30.9836, 29.5225,\n",
      "         33.3546],\n",
      "        [25.3033, 30.3509, 27.9769, 26.9378, 29.1908, 29.6951, 30.1587, 33.2901,\n",
      "         24.2454, 27.4103, 28.8624, 28.1956, 28.2815, 24.1305, 29.6105, 23.2230,\n",
      "         28.7186, 26.2095, 27.1663, 27.2914, 25.4981, 27.3705, -5.7822, -0.0000,\n",
      "         -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "         -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "         -0.0000]], device='cuda:0')\n",
      "current_logits: tensor([[[10.1872, -9.2653, 12.5619,  ..., -9.2280, -9.4637, -9.3478],\n",
      "         [18.3688, -9.4639, 26.1474,  ..., -9.4509, -9.6070, -9.4042],\n",
      "         [16.7981, -8.4010, 10.1527,  ..., -8.5817, -8.5789, -8.6190],\n",
      "         ...,\n",
      "         [15.5656, -7.1599, 17.2097,  ..., -7.1016, -7.2832, -7.2053],\n",
      "         [17.0417, -8.2916, 21.1121,  ..., -7.9137, -8.1858, -8.3586],\n",
      "         [33.3546, -7.4864, 13.4063,  ..., -7.5589, -7.4512, -7.4859]],\n",
      "\n",
      "        [[10.4974, -8.5801, 11.5164,  ..., -8.5373, -9.0073, -8.6803],\n",
      "         [14.3768, -5.2486, 13.2628,  ..., -5.0781, -5.0712, -5.0118],\n",
      "         [18.4907, -7.6095, 27.9769,  ..., -7.6975, -7.4529, -7.6503],\n",
      "         ...,\n",
      "         [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000]]],\n",
      "       device='cuda:0')\n",
      "next_state_value: tensor([[22.3139, 26.1632, 30.5859, 32.3264, 29.8953, 30.1727, 31.6067, 33.1091,\n",
      "         34.7827, 35.9925, 34.1643, 29.9294, 30.4358, 31.0573, 32.4314, 30.3382,\n",
      "         31.4582, 28.7966, 28.3927, 30.0611, 30.5645, 32.6198, 32.7259, 33.7913,\n",
      "         31.2187, 35.8044, 30.8452, 36.3358, 31.0380, 33.2752, 33.3833, 34.9673,\n",
      "         29.7956, 34.5706, 30.6824, 33.2035, 29.3619, 28.1294, 30.9851, 29.5230,\n",
      "         33.3568],\n",
      "        [25.4384, 30.3510, 28.2724, 27.2229, 29.7624, 29.7167, 30.1606, 33.2902,\n",
      "         25.0482, 27.4536, 28.8649, 28.2588, 28.5341, 25.4699, 29.6106, 23.9742,\n",
      "         28.7204, 26.3404, 27.4252, 27.2921, 25.6383, 27.4303, 32.5262,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000]], device='cuda:0')\n",
      "t_logits: tensor([[[  9.4989,  -9.9536,  11.8735,  ...,  -9.9163, -10.1520, -10.0361],\n",
      "         [ 16.5895, -11.2432,  24.3681,  ..., -11.2302, -11.3862, -11.1834],\n",
      "         [ 14.1982, -11.0009,   7.5529,  ..., -11.1815, -11.1787, -11.2189],\n",
      "         ...,\n",
      "         [ 13.8570,  -8.8684,  15.5011,  ...,  -8.8102,  -8.9917,  -8.9139],\n",
      "         [ 15.7192,  -9.6141,  19.7896,  ...,  -9.2361,  -9.5082,  -9.6810],\n",
      "         [ 31.1847,  -9.6563,  11.2364,  ...,  -9.7288,  -9.6212,  -9.6558]],\n",
      "\n",
      "        [[  8.9188, -10.1587,   9.9378,  ..., -10.1159, -10.5859, -10.2589],\n",
      "         [ 11.0736,  -8.5518,   9.9597,  ...,  -8.3813,  -8.3743,  -8.3149],\n",
      "         [ 16.3962,  -9.7040,  25.8823,  ...,  -9.7921,  -9.5474,  -9.7448],\n",
      "         ...,\n",
      "         [ 12.2850, -11.1306,   7.2364,  ..., -11.0535, -11.1218, -11.1635],\n",
      "         [ 12.2850, -11.1306,   7.2364,  ..., -11.0535, -11.1218, -11.1635],\n",
      "         [ 12.2850, -11.1306,   7.2364,  ..., -11.0535, -11.1218, -11.1635]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "full_ids = outputs.sequences\n",
    "attention_mask = (full_ids != tokenizer.pad_token_id)\n",
    "model_inputs = {\n",
    "    \"input_ids\": full_ids,\n",
    "    \"attention_mask\": attention_mask,\n",
    "}\n",
    "scores = reward_fn(model, model_inputs, inputs[\"input_ids\"])\n",
    "gen_ids = full_ids[:, inputs[\"input_ids\"].shape[1]:]\n",
    "assert(gen_ids.shape == scores.shape)\n",
    "scores_ours = reward_fn_ours(model, model_inputs, inputs[\"input_ids\"])\n",
    "# print(f\"shape: {gen_ids.shape}\")\n",
    "# print(f\"full_ids:\\n{gen_ids}\")\n",
    "# print(f\"scores:\\n{scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection_value = torch.gather(logits[:, :-1, :], -1, model_inputs[\"input_ids\"][:, input_ids.size(-1):, None]).squeeze(-1)\n",
    "# current_logits = logits[:, :-1, :]\n",
    "# next_state_value = torch.logsumexp(current_logits, dim=-1)\n",
    "# next_state_value = next_state_value * mask[:, :-1]\n",
    "# scores = selection_value - next_state_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.7285e-01, -1.5800e-02, -7.8485e-02, -7.2746e-03, -3.1907e-01,\n",
      "         -1.6081e-02, -1.5259e-04, -1.5259e-05, -3.0136e-04, -2.5597e-02,\n",
      "         -1.1826e-04, -6.8733e-02, -7.8337e-02, -7.1148e-01, -2.0374e-02,\n",
      "         -2.9123e-02, -1.1401e-01, -7.4022e-01, -3.2908e-01, -2.1381e-03,\n",
      "         -5.7602e-04, -9.2278e-03, -1.6373e-02, -7.7438e-04, -4.5201e-01,\n",
      "         -3.5133e-03, -2.0189e-02, -1.3443e-02, -2.7040e-02, -1.1406e-03,\n",
      "         -4.5666e-01, -5.7220e-05, -8.1139e-03, -1.2741e-03, -5.8102e-01,\n",
      "         -2.6703e-05, -2.7121e-02, -9.2754e-03, -1.5488e-03, -5.7602e-04,\n",
      "         -2.1667e-03],\n",
      "        [-1.3506e-01, -1.1826e-04, -2.9558e-01, -2.8511e-01, -5.7159e-01,\n",
      "         -2.1654e-02, -1.8082e-03, -7.2479e-05, -8.0278e-01, -4.3291e-02,\n",
      "         -2.4776e-03, -6.3187e-02, -2.5258e-01, -1.3395e+00, -1.2779e-04,\n",
      "         -7.5118e-01, -1.7395e-03, -1.3085e-01, -2.5898e-01, -7.0000e-04,\n",
      "         -1.4019e-01, -5.9839e-02, -3.8308e+01, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00]], device='cuda:0')\n",
      "tensor([[-7.7285e-01, -1.5800e-02, -7.8487e-02, -7.2734e-03, -3.1907e-01,\n",
      "         -1.6081e-02, -1.5293e-04, -1.6451e-05, -3.0251e-04, -2.5597e-02,\n",
      "         -1.2004e-04, -6.8732e-02, -7.8339e-02, -7.1147e-01, -2.0376e-02,\n",
      "         -2.9123e-02, -1.1401e-01, -7.4022e-01, -3.2908e-01, -2.1391e-03,\n",
      "         -5.7693e-04, -9.2261e-03, -1.6372e-02, -7.7254e-04, -4.5201e-01,\n",
      "         -3.5117e-03, -2.0190e-02, -1.3444e-02, -2.7040e-02, -1.1389e-03,\n",
      "         -4.5666e-01, -5.8649e-05, -8.1135e-03, -1.2732e-03, -5.8101e-01,\n",
      "         -2.6703e-05, -2.7121e-02, -9.2760e-03, -1.5494e-03, -5.7573e-04,\n",
      "         -2.1671e-03],\n",
      "        [-1.3506e-01, -1.1873e-04, -2.9558e-01, -2.8511e-01, -5.7159e-01,\n",
      "         -2.1654e-02, -1.8077e-03, -7.0927e-05, -8.0278e-01, -4.3292e-02,\n",
      "         -2.4768e-03, -6.3186e-02, -2.5258e-01, -1.3395e+00, -1.2767e-04,\n",
      "         -7.5118e-01, -1.7401e-03, -1.3085e-01, -2.5898e-01, -7.0023e-04,\n",
      "         -1.4019e-01, -5.9839e-02, -3.8308e+01, -3.8029e+01, -3.8029e+01,\n",
      "         -3.8029e+01, -3.8029e+01, -3.8029e+01, -3.8029e+01, -3.8029e+01,\n",
      "         -3.8029e+01, -3.8029e+01, -3.8029e+01, -3.8029e+01, -3.8029e+01,\n",
      "         -3.8029e+01, -3.8029e+01, -3.8029e+01, -3.8029e+01, -3.8029e+01,\n",
      "         -3.8029e+01]], device='cuda:0')\n",
      "True\n",
      "tensor(1.8254e-06, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "print(scores_ours)\n",
    "print(torch.allclose(scores[0], scores_ours[0], atol=1e-05))\n",
    "print((scores[0] - scores_ours[0]).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_lens(mask):\n",
    "    mask = mask.float()\n",
    "    print(f'mask.float():\\n{mask}')\n",
    "    lens = torch.cumsum(mask, dim=-1)      # faster way        \n",
    "    print(f'lens cumsum:\\n{lens}')\n",
    "    lens = mask - lens + lens[:, -1:None]  # faster way\n",
    "    print(f'mask - lens:\\n{lens}')\n",
    "    lens = torch.masked_fill(lens, lens==0, 1)\n",
    "    print(f'lens masked_fill:\\n{lens}')\n",
    "    return lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = inputs[\"input_ids\"].shape[1]\n",
    "mask = model_inputs[\"attention_mask\"]\n",
    "mask = mask[:, context_length:]\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask.float():\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "lens cumsum:\n",
      "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
      "         15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28.,\n",
      "         29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41.],\n",
      "        [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
      "         15., 16., 17., 18., 19., 20., 21., 22., 22., 22., 22., 22., 22., 22.,\n",
      "         22., 22., 22., 22., 22., 22., 22., 22., 22., 22., 22., 22., 22.]],\n",
      "       device='cuda:0')\n",
      "mask -lens:\n",
      "tensor([[41., 40., 39., 38., 37., 36., 35., 34., 33., 32., 31., 30., 29., 28.,\n",
      "         27., 26., 25., 24., 23., 22., 21., 20., 19., 18., 17., 16., 15., 14.,\n",
      "         13., 12., 11., 10.,  9.,  8.,  7.,  6.,  5.,  4.,  3.,  2.,  1.],\n",
      "        [22., 21., 20., 19., 18., 17., 16., 15., 14., 13., 12., 11., 10.,  9.,\n",
      "          8.,  7.,  6.,  5.,  4.,  3.,  2.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
      "       device='cuda:0')\n",
      "lens masked_fill:\n",
      "tensor([[41., 40., 39., 38., 37., 36., 35., 34., 33., 32., 31., 30., 29., 28.,\n",
      "         27., 26., 25., 24., 23., 22., 21., 20., 19., 18., 17., 16., 15., 14.,\n",
      "         13., 12., 11., 10.,  9.,  8.,  7.,  6.,  5.,  4.,  3.,  2.,  1.],\n",
      "        [22., 21., 20., 19., 18., 17., 16., 15., 14., 13., 12., 11., 10.,  9.,\n",
      "          8.,  7.,  6.,  5.,  4.,  3.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[41., 40., 39., 38., 37., 36., 35., 34., 33., 32., 31., 30., 29., 28.,\n",
       "         27., 26., 25., 24., 23., 22., 21., 20., 19., 18., 17., 16., 15., 14.,\n",
       "         13., 12., 11., 10.,  9.,  8.,  7.,  6.,  5.,  4.,  3.,  2.,  1.],\n",
       "        [22., 21., 20., 19., 18., 17., 16., 15., 14., 13., 12., 11., 10.,  9.,\n",
       "          8.,  7.,  6.,  5.,  4.,  3.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_lens(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "tensor([[12092,     2,  1284,   271, 14980,  3448,  1566,    13,   309,  1053,\n",
      "           626,   452, 10450,    13,   533,   309,  1353, 15415,  6283,   285,\n",
      "          4704,   281, 10073,   368,   342,   667,  3533,   390,  8892,   368,\n",
      "           778,   452,    15,  1359,   476,   309,  1361,   368,  3063,    32,\n",
      "             0],\n",
      "        [ 4527,  2282,     2,   309,  1871,   320,  5211,   281,   320,   634,\n",
      "          3331,    15,  1737,   513,   368,   751,   281,   513,   323,   794,\n",
      "            32,     0,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1]], device='cuda:0')\n",
      "seq length:\n",
      "tensor([40, 21], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from trl.trainer.utils import first_true_indices\n",
    "query_response = model_inputs[\"input_ids\"]\n",
    "context_length = inputs[\"input_ids\"].shape[1]\n",
    "response = query_response[:, context_length:]\n",
    "sequence_length = first_true_indices(response == tokenizer.pad_token_id) - 1\n",
    "print(f'response:\\n{response}')\n",
    "print(f'seq length:\\n{sequence_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1])\n",
      "tensor([40, 22], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "rewards = scores_ours\n",
    "actual_start = torch.arange(rewards.size(0))\n",
    "print(actual_start)\n",
    "sequence_length_p1 = sequence_length + 1\n",
    "actual_end = torch.where(sequence_length_p1 < rewards.size(1), sequence_length_p1, sequence_length)\n",
    "print(actual_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 41])\n",
      "tensor([-2.1671e-03, -3.8308e+01], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(rewards.shape)\n",
    "print(rewards[[actual_start, actual_end]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "args",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
